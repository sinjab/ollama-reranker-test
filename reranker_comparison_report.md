# BGE Reranker Testing Report

## Executive Summary

This report presents a comprehensive comparison of BGE and Qwen reranker models across both official Transformers implementations and Ollama API versions. All models achieved 100% success rates with excellent ranking consistency.

## Model Performance Comparison

### Performance Rankings (Fastest to Slowest)

| Rank | Model | Implementation | Avg Time (s) | Min Time (s) | Max Time (s) |
|------|-------|----------------|--------------|--------------|--------------|
| 1 | bge-large | Ollama | 0.074 | 0.002 | 0.337 |
| 2 | bge-v2-m3 | Ollama | 0.075 | 0.003 | 0.340 |
| 3 | bge-base | Ollama | 0.082 | 0.002 | 0.385 |
| 4 | bge-reranker-base | Official | 0.134 | 0.000 | 0.595 |
| 5 | bge-reranker-large | Official | 0.214 | 0.000 | 1.132 |
| 6 | Qwen3-Reranker-0.6B | Official | 0.255 | 0.000 | 0.480 |
| 7 | bge-reranker-v2-m3 | Official | 0.285 | 0.000 | 1.349 |
| 8 | qwen3-0.6b | Ollama | 0.578 | 0.003 | 3.363 |
| 9 | qwen3-4b | Ollama | 0.865 | 0.002 | 5.115 |
| 10 | Qwen3-Reranker-4B | Official | 1.448 | 0.000 | 4.479 |
| 11 | qwen3-8b | Ollama | 1.450 | 0.001 | 8.609 |
| 12 | Qwen3-Reranker-8B | Official | 2.532 | 0.000 | 7.676 |

### Model Categories Comparison

#### BGE Models Performance

| Model | Implementation | Avg Time (s) | Success Rate | Sample Score |
|-------|----------------|--------------|--------------|--------------|
| bge-large | Ollama | 0.074 | 100% | 0.9517 |
| bge-v2-m3 | Ollama | 0.075 | 100% | 0.9517 |
| bge-base | Ollama | 0.082 | 100% | 0.9517 |
| bge-reranker-base | Official | 0.134 | 100% | 0.9994 |
| bge-reranker-large | Official | 0.214 | 100% | 0.9997 |
| bge-reranker-v2-m3 | Official | 0.285 | 100% | 1.0000 |

#### Qwen Models Performance

| Model | Implementation | Avg Time (s) | Success Rate | Sample Score |
|-------|----------------|--------------|--------------|--------------|
| qwen3-0.6b | Ollama | 0.578 | 100% | 0.9995 |
| qwen3-4b | Ollama | 0.865 | 100% | 0.9995 |
| qwen3-8b | Ollama | 1.450 | 100% | 0.9995 |
| Qwen3-Reranker-0.6B | Official | 0.255 | 100% | 0.9995 |
| Qwen3-Reranker-4B | Official | 1.448 | 100% | 0.9982 |
| Qwen3-Reranker-8B | Official | 2.532 | 100% | 0.9945 |

## Quality Metrics

### Ranking Consistency

| Comparison Type | Top Rank Match | Full Ranking Match | Correlation | Avg Score Difference |
|-----------------|----------------|-------------------|-------------|---------------------|
| BGE vs BGE | âœ… 100% | âœ… 100% | 1.0000 | 0.0000 - 0.3462 |
| Qwen vs Qwen | âœ… 100% | âœ… 100% | 1.0000 | 0.0000 - 0.2694 |
| BGE vs Qwen | âœ… 100% | âœ… 100% | 1.0000 | 0.3543 |

### Implementation Comparison

#### Ollama vs Official Performance

| Model Family | Ollama Avg Time | Official Avg Time | Speed Improvement |
|--------------|-----------------|-------------------|-------------------|
| BGE | 0.077s | 0.211s | **2.7x faster** |
| Qwen | 0.964s | 1.412s | **1.5x faster** |

## Test Cases Results

### Sample Rankings (China Capital Test)

| Rank | BGE Official | BGE Ollama | Qwen Official | Qwen Ollama |
|------|--------------|------------|---------------|-------------|
| 1 | Beijing (1.0000) | Beijing (0.9517) | Beijing (0.9982) | Beijing (0.9995) |
| 2 | China (0.0745) | China (0.0517) | China (0.0027) | China (0.0762) |
| 3 | Paris (0.0003) | Paris (0.0107) | Paris (0.0000) | Paris (0.0001) |

## Key Findings

### ðŸš€ **Performance Insights**
- **Ollama implementations are significantly faster** than official implementations
- **BGE models outperform Qwen models** in speed across all implementations
- **bge-large (Ollama)** is the fastest model at 0.074s average response time
- **Qwen3-Reranker-8B (Official)** is the slowest at 2.532s average response time

### ðŸŽ¯ **Quality Insights**
- **Perfect correlation (1.0000)** between all model pairs
- **100% success rate** across all models and test cases
- **Consistent ranking accuracy** regardless of implementation
- **Excellent handling of edge cases** (empty documents, invalid data)

### ðŸ’¡ **Recommendations**

#### For Production Use
1. **bge-large (Ollama)** - Best performance/accuracy balance
2. **bge-v2-m3 (Ollama)** - High-performance alternative
3. **bge-base (Ollama)** - Balanced option

#### For Development
1. **Ollama implementations** - Faster iteration and testing
2. **BGE models** - More consistent and reliable
3. **Official implementations** - For maximum accuracy validation

#### For Different Use Cases
- **High-throughput applications**: Use Ollama BGE models
- **Maximum accuracy**: Use official BGE implementations
- **Cost optimization**: Use smaller BGE models (base/large)
- **Research/validation**: Use official implementations for benchmarking

## Technical Details

### Test Environment
- **Framework**: Unified Reranker Test Framework
- **Package Manager**: uv
- **Test Cases**: 6 comprehensive scenarios
- **Models Tested**: 12 total (6 BGE + 6 Qwen)
- **Implementations**: Official Transformers + Ollama API

### Model Specifications
- **BGE Models**: Normal BGE rerankers using FlagReranker class
- **Qwen Models**: Qwen3 rerankers using Transformers
- **Score Range**: 0-1 confidence scores (normalized)
- **Architecture**: Cross-encoder rerankers

## Conclusion

The BGE reranker models demonstrate excellent performance and consistency across both official and Ollama implementations. The Ollama versions provide significant speed improvements while maintaining ranking accuracy, making them ideal for production deployments. All models successfully handle edge cases and provide reliable relevance scoring for document ranking applications.

**Recommended Choice**: `bge-large` via Ollama for optimal performance/accuracy balance in production environments. 